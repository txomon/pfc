% !TeX spellcheck = es_ES
% !TeX root = main.tex

\chapter{Introducción}

En los últimos años, las tecnologías informáticas de la comunicación están revolucionando la manera de comunicarse del mundo entero. Tener acceso a Internet se ha convertido en algo necesario para poder ponerse en contacto con el resto del mundo.

Cada vez hay más dispositivos conectados, con el consiguiente crecimiento del tráfico en todas las redes. Incluso empresas que antes contrataban redes privadas para sus comunicaciones, ahora utilizan Internet para interconectar sus redes.

Como en cualquier servicio crítico el mantenimiento debe ser proactivo y por ello se han creado métodos para garantizar la máxima eficiencia de las comunicaciones. Además se debe garantizar la seguridad en la red y la detección instantánea de problemas, asegurando así la \textit{QoS} (\textit{Quality of Service}, Calidad de Servicio).

Para la securización de la red se implantan \textit{firewalls}, \textit{proxys}, e \textit{IDS}s (\textit{Intrusion Detection System}, Sistema de Detección de Intrusión), que se encargan de evitar accesos externos no autorizados a la red, controlar el tráfico saliente, y detectar posibles atacantes dentro de la red.

El método para medir la calidad de las comunicaciones y tomar las acciones necesarias para mejorarla, es la medición de parámetros de \textit{QoS}, tales como el retardo de los paquetes, los errores de transmisión, los tipos más comunes de tráfico, cálculo de rutas óptimas, etc.

Son varias las soluciones comerciales que implementan estos servicios pero actualmente no hay ninguna que implemente todo en un mismo sistema. Además, no hay ningún producto de código libre que aproveche al máximo la posible eficiencia del equipo, haciendo un análisis \textit{online}\footnote{Online se refiere a hacer el análisis mientras se captura, en vez de capturar, guardar y luego analizar.}.

En el grupo de investigación \textit{Network Quality and Security (NQAS)} se ha diseñado un sonda que implementa algunas de las citadas funcionalidades. En el diseño de la misma se ha contemplado la posibilidad de, más adelante, poder ampliarla de una manera sencilla. Como valor añadido fundamental, aprovecha al máximo los recursos disponibles, ya que ha sido programado de una manera que permita la ejecución multi-hilo.

Este prototipo se llama Ksensor\cite{KABO05}, aunque no es el primero que se ha creado. La línea de investigación principal, llamada hi-sensor, ha ido haciendo cada vez más complejo el diseño y la programación del prototipo con el objetivo de mejorar la eficiencia del sistema.

A grandes rasgos, la sonda en un principio se diseñó de forma que la aplicación fuera un programa de usuario, que capturaba a través de una librería estándar para la captura de paquetes de forma promiscua \code{libpcap}. La sonda resultante se puede encontrar descrita en el proyecto Adviser\cite{AABS04}. Se utilizaron también las librerías para tener computación multi-hilo, obteniendo unos resultados prometedores.

Cuando se empezaron a analizar redes de alta velocidad en saturación se vio que había un problema: El equipo estaba continuamente capturando y no había espacio para el análisis. Para solucionar este problema, se migró a espacio de kernel.

El kernel es la base que hace que todos los programas funcionen. Es el núcleo de cualquier sistema operativo moderno, el cual que se encarga de gestionar los dispositivos y recursos del ordenador para ofrecer una interfaz libre de detalles a los programas. Además, también se encarga de hacer que varios programas se ejecuten de una manera que proporcione al usuario la sensación de que están en ejecución simultánea. A parte de eso, se encarga de que los programas sean capaces de hacer un direccionamiento virtual de una forma transparente a ellos, manejando eficazmente una MMU (\textit{Memory Management Unit}, Unidad de Gestión de Memoria), de manera que permite que estos sea posible compilarlos como si fueran a ejecutarse en un sistema que solo ocupan ellos.

En general, del diseño de un buen kernel dependerá la eficiencia del sistema. En nuestro caso, el diseño del kernel no está hecho para nuestro tipo de sistema, una sonda de tráfico, pero a través de una serie de modificaciones, podemos cambiar el comportamiento del sistema para amoldarlo a nuestro caso de uso. Todo sea dicho, la eficiencia del kernel actual es buena para los sistemas operativos de carácter general, en los que capturar los paquetes de uno mismo es suficiente, y que es una cantidad pequeña en comparación con el tráfico de la red.

El cometido del sistema que queremos es únicamente para capturar y procesar paquetes y por lo tanto, la máxima eficiencia se puede describir como el equilibrio entre el tiempo en el que el ordenador esta capturando y el que está analizando. Se tienen que capturar exactamente los paquetes que se van a analizar.

La implementación actual del sistema ha quedado obsoleta para las versiones del kernel actual, ya que el tratamiento de los paquetes se hace de una forma diferente. Ahora se crean \textit{superpaquetes} ensamblando desde la captura los paquetes que tienen una serie de parámetros iguales, como pueden ser la IP de origen, IP de destino, puerto TCP destino y origen. De esta manera, al pasar un único paquete (aunque grande) a la pila de protocolos, se acelera su tratamiento, ya que las copias de los paquetes se pueden hacer en una única transacción.

Por lo tanto, el proyecto se enfoca a mejorar el anterior diseño para adaptarlo a la nueva manera de hacer las cosas, crear una serie de herramientas para validar el diseño y adaptar el proyecto a los estándares de facto existentes en kernel.org para hacer posible la liberación pública del código. La tarea de mayor relevancia en estos momentos es posibilitar un estudio comparativo entre un sistema normal, con las aplicaciones de análisis de tráfico disponibles públicamente y la aplicación Ksensor.