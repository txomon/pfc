% !TeX spellcheck = es_ES
% !TeX root = main.tex

\chapter{Análisis de alternativas}
En este capítulo se expondrán primeramente las especificaciones y requerimientos básicos del presente proyecto, describiendo brevemente la arquitectura inicial de la cual se parte en el diseño de la sonda e indicando los condicionantes que se le imponen al diseño inicialmente.

Se expondrán asimismo las mejoras que se pretenden conseguir con el nuevo diseño, indicando los requisitos que debe cumplir el kernel del sistema operativo para llevarlas a cabo. Para esto, se explicarán las alternativas de diseño que se deben considerar en la realización del proyecto y se hará un estudio para determinar cuál es la óptima en cada caso.

A lo largo del diseño se han de tomar decisiones que van a contribuir de forma decisiva al éxito, o fracaso, del proyecto. Por esta razón, conviene analizar minuciosamente las alternativas que existen. No es necesario tener en cuenta todas y cada una de las posibilidades pero sí las que puedan resultar críticas a la hora de aportar una solución.

Así pues, se partirá de los requerimientos apuntados en el primer apartado para a continuación plantear las alternativas concernientes a los puntos más críticos del diseño, y una vez tomadas las decisiones oportunas, se pasará, en el capítulo de Diseño, a describir con mayor detenimiento la solución general propuesta, incidiendo especialmente en las partes discutidas en este capítulo.

\section{Especificaciones y requerimientos básicos}
\label{sec:especificaciones-y-requerimientos-básicos}
En el presente proyecto se plantea el desarrollo de una sonda de análisis de tráfico a nivel de kernel, para lo cual se parte de un diseño previo de la sonda (Ksensor), realizado en un proyecto anterior \cite{KABO05}. La sonda es el núcleo de una arquitectura dedicada al análisis de tráfico, la cual incluye además de la sonda, módulos adicionales que tienen relación directa con él, como el parser o el OPM. En la realización de este proyecto, tras analizar exhaustivamente el funcionamiento de los módulos externos, y su funcionamiento, no se ha considerado que sea necesario su reimplementación.

Por otro lado, conviene especificar las mejoras de diseño que se pretenden obtener con la migración de Ksensor, en base a las cuales se ha justificado la realización de este proyecto. El cumplimiento o no de dichas mejoras, condicionarán el éxito o fracaso del proyecto, por lo que se plantearán también las mejoras que ha tenido el kernel de Linux para poder obtenerlas.

\subsection{Arquitectura de partida}
En la siguiente figura, se puede ver la arquitectura actual del sistema implementado Ksensor. Aunque los módulos que componen el sistema vienen de un sistema anterior llamado Adviser, se explicarán brevemente a continuación.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{arquitectura-previa}
\caption{Esquema de la arquitectura previa de Ksensor}
\label{fig:arquitectura-previa}
\end{figure}

En la figura de la \reference{fig:arquitectura-previa}{arquitectura previa} se pueden observar los módulos que componen el sistema. Los paquetes se capturan en las tarjetas de red y el módulo de captura se encarga de procesar directamente los paquetes, sirviéndolos cuando se solicita a las instancias del módulo de procesamiento.

La sonda es el núcleo del sistema de análisis. El resto de módulos pretenden bien configurar su comportamiento (parser) o bien recoger los resultados del procesamiento realizado (OPM). En cualquier caso, el nexo de unión entre todos ellos es la memoria interna de la sonda, a la que también nos referiremos como mapa de memoria. En el mapa de memoria se almacena la lógica de decisión que posteriormente se utilizará tanto en el módulo de captura, para decidir si un paquete debe ser capturado, como en el módulo de procesamiento de la sonda para determinar el análisis que se ha de realizar al mismo.

El parser es el encargado de cargar en la memoria de la sonda la información que éste requiere para funcionar de forma correcta. Para ello, el parser toma como entrada un fichero de reglas en XML especificado por el administrador del sistema. El fichero de reglas se escribe utilizando un lenguaje propio, el cual se ha definido teniendo en cuenta muchas características de entornos de captura de tráfico como sistemas de detección de intrusión, cortafuegos, etc.

El parser lee e interpreta el fichero de reglas especificado por el administrador del sistema y lo traduce al formato que entiende la sonda, almacenando en el mapa de memoria la lógica adecuada y la información de entorno necesaria para el análisis de tráfico. Para ello, se crean varias listas enlazadas: una para el árbol de nodos, otra para los tipos de datos, acciones periódicas, etc. También se reserva un espacio para almacenar las variables, que será donde la sonda deposite la información y las estadísticas que se le han pedido.

Si el parser es la interfaz de entrada a la sonda, el módulo de procesamiento offline (OPM) constituye su interfaz de salida. El módulo de procesamiento offline es el encargado de recolectar toda la información que se obtiene como resultado del análisis del tráfico y de formatearla para su posterior procesamiento fuera de la sonda.

En el nuevo diseño se va a mantener este diseño de los módulos, ya que se ha comprobado a través de las baterías de pruebas de que no plantea ningún tipo de degradación de rendimiento, y además, permite que la aplicación Ksensor pueda estar en ejecución o no, haciendo uso de la propiedad de modularidad del kernel de Linux.

\subsection{Mejoras del diseño}
Este proyecto propone una adaptación del diseño existente de Ksensor a una versión de Linux actual. Preservando su compatibilidad con las herramientas externas pero mejorando el funcionamiento interno, la integración en el árbol de kernel, y creando nuevas herramientas que permitan estudiar el comportamiento del sistema, tanto con Ksensor funcionando como deshabilitado.

Con un análisis exhaustivo del código de las rutinas de recepción de paquetes, se ha llegado a la conclusión de que aún con el sistema en saturación, hay recursos que se destinan a otros procesos de red, como el envío de paquetes. Por ello, es necesario, no tanto cambiar el diseño de Ksensor, si no crear las herramientas que permitan tener acotados los procesos que no nos interesan para poder planificar nuestro sistema con los parámetros óptimos, en vez de hacerlo a prueba y error.

También se pretende mejorar el rendimiento de captura, adaptando el número de paquetes a capturar a las necesidades actuales del sistema, ya que así se evita que la cola varíe de tamaño en forma de dientes de sierra, o que se intenten capturar paquetes que no deberían entrar en la cola. En el apartado de diseño se ampliarán más estos conceptos.

\subsection{Requerimientos de la migración}
Uno de los mayores propósitos de la migración es aprovechar al máximo todas las herramientas disponibles para la ejecución del proyecto, y para facilitar su desarrollo. Concretamente, se van a utilizar las herramientas que utilizan los desarrolladores de kernel, tales como un sistema de control de versiones, adaptando la manera en la que se tiene estructurado el código para una óptima utilización de las herramientas. También se va a establecer una forma uniforme de integración, ya que no serán solo mejoras a Ksensor, si no también utilidades que pueden tener valor a la hora de diagnosticar sistemas.

\section{Estudio de alternativas de diseño}
En este punto se estudian las diferentes alternativas de migración que se tendrán que considerar en la ejecución del proyecto. En una primera aproximación, se puede observar que muchas de estas alternativas tienen dependencias entre sí, por lo que las decisiones que se tomen para una podrán influir de alguna manera sobre las siguientes.

Para cada alternativa se establecerán diversos criterios que nos permitirán seleccionar la opción más apropiada. Se tendrán en cuenta también los requerimientos iniciales señalados en el apartado \reference{sec:especificaciones-y-requerimientos-básicos}{Especificaciones y requerimientos básicos}.

\subsection{Métodos para enviar información usuario}
Con objetivo de pasar al usuario información de distinta índole, es necesario hacer un estudio de las diferentes opciones que hay disponibles actualmente.  A continuación se explicarán de una forma breve cuales son los diferentes sistemas que se utilizan en Linux, ya que aunque para sacar poca información está bien utilizar la salida estándar de mensajes en kernel, para sacar mucha información es totalmente ineficaz.

\subsubsection{Estudio de las alternativas}
\begin{description}
\item [Mensaje por salida estándar]
La forma más fácil, que no requiere ningún tipo de programación ni configuración es la salida estándar del sistema, a través de la función printk, la cual almacena la salida en \code{/var/log/} en los diferentes ficheros relativos al kernel que se pueden encontrar ahí, todo depende de la prioridad que se le de al mensaje.

El problema con este tipo de salida es que está mezclado con el resto de salidas del kernel, y por lo tanto requiere de una lógica de filtrado en el lector. Además, tiene unos búferes muy ajustados, y requiere de un gran procesamiento.

\item [Fichero virtual utilizando procfs estándar]
La forma más común de sacar información del kernel es a través de ficheros en el sistema de ficheros de \textit{/proc}, procfs. Es el sistema más sencillo, y es el que se utiliza para la mayoría de las transacciones para proveer información a los programas. Por ejemplo, todos los procesos que hay en el sistema junto se representan en una carpeta virtual en /proc/<pid>.

De ahí, aplicaciones como \textit{ps}, \textit{top}, \textit{gnome-system-monitor}, etc. utilizan esta interfaz para informarse sobre los procesos existentes. Actualmente, Ksensor utiliza esa misma interfaz para sacar información de estadísticas internas e información varia, como las interfaces actuales de captura o el estado del mismo.

El problema de esta implementación es que el fichero debe ser generado completamente cada vez que se requiere, lo cual es aceptable para ficheros cortos, pero impensable para, por ejemplo el módulo de traceo, que necesita tener ficheros virtuales de cientos de megas.

\item [Fichero virtual con seq\_file]
Esta implementación de fichero virtual permite recorrer de una manera iterativa una secuencia sin predefinir. Está pensada con una función inicializadora, una función para pasar al siguiente punto, una función para mostrar y una última función para terminar.

Esta interfaz permite que se pueda crear el fichero bajo demanda, e incluso, se le instruya al kernel que solo genere las entradas específicas que se van a consultar.

\item [Fichero físico]
Una opción que es digna de mención por ser la opción más directa es guardar datos en ficheros físicos. Es una opción que tiene bastantes problemas de implementación, ya que al estar dentro del sistema operativo, tienes que tratar con una interfaz interna a ficheros.

Por otra parte, esta solución sería adecuada en caso de requerir guardar ficheros de gran tamaño. Si bien es cierto que el disco duro tiene un acceso muy lento, es la única alternativa cuando el tamaño supera la memoria física del ordenador

\end{description}

\subsubsection{Criterio de la selección}
A la hora de seleccionar entre las diferentes alternativas disponibles la solución óptima a este problema se plantea una variable a tener en cuenta de dimensionamiento. Por una parte, el traceador está pensado para hacer gran cantidad de medidas y estas requieren de ficheros grandes, por otro lado, las estadísticas contienen valores de diferentes tipos pero sin ninguna relación entre ellos necesariamente.

Debido a lo expuesto anteriormente, se crearán criterios respecto al tamaño de la información que se va a sacar, la complejidad de la programación de la interfaz y la efectividad de la comunicación, expuestos a continuación

\begin{description}
\item[Tamaño de los datos [40\%]]
Este es el parámetro más importante para la selección de un criterio adecuado. En él queda reflejada la dimensión que debe tener el fichero para justificar su uso. 

\item[Complejidad y rendimiento [30\%]]
Aunque puedan ser igualmente efectivas unas salidas que otras, siempre suele haber una interfaz que es más difícil de implementar que otra, añadiendo un sobrecoste en caso de no ser necesaria. Además, también debe tenerse en cuenta que puede ser más sencilla, pero tener un coste desmesurado en el rendimiento.

\item[Facilidad de uso[30\%]]
Este componente es clave en la elección de la interfaz, ya que representa la facilidad que el usuario tiene para utilizar la interfaz y la efectividad de la comunicación. Por ejemplo, no sería igual de sencilla implementar la salida de datos a través de un puerto serie, el cual necesitaría de un dispositivo externo para su realización, que crear un fichero en el cual el usuario pueda leer los datos que le interesen, con utilidades estándar del sistema, como pueden ser awk, sed, cat, etc.
\end{description}

\subsubsection{Selección de la solución}
Como son diferentes las necesidades de la solución, se han dispuesto los casos necesarios:

\paragraph{En caso de salida de menos de 500MB y más de 1KB}
\begin{center}
\rowcolors{1}{gray}{white}
\begin{tabular}{|c*{5}{c|}}
\hline Criterio                  & Ponderación & printk & procfs & seq\_file & inode \\ 
\hiderowcolors
\hline Tamaño de los datos       &    40\%     &  0/40  & 10/40  &  35/40   & 40/40 \\ 
\hline Complejidad y rendimiento &    30\%     & 10/30  & 25/30  &  25/30   & 20/30 \\
\hline Facilidad                 &    30\%     & 10/30  & 30/30  &  30/30   & 20/30 \\
\hline Total               &    100\%    & 20/100 & 65/100 &  90/100  & 80/100\\
\hline 
\end{tabular}
\end{center}

\paragraph{En caso de salida de menos de 1KB}
\begin{center}
\rowcolors{1}{gray}{white}
\begin{tabular}{|c*{5}{c|}}
\hline Criterio                  & Ponderación & printk & procfs & seq\_file & inode \\ 
\hiderowcolors
\hline Tamaño de los datos       &    40\%     & 30/40  & 40/40  &  25/40   & 0/40 \\ 
\hline Complejidad y rendimiento &    30\%     & 15/30  & 30/30  &  25/30   & 0/30 \\
\hline Facilidad                 &    30\%     & 20/30  & 30/30  &  30/30   & 20/30 \\
\hline Total               &    100\%    & 65/100 &100/100 &  80/100  & 20/100\\
\hline 
\end{tabular}
\end{center}

Se ha decidido utilizar la interfaz de seq\_file para el módulo de trazas. Una implementación que se espera sea suficiente con sacar un máximo de 500MB de datos. Actualmente, con las necesidades de guardar información, los archivos de salida de las pruebas de modelado se estima sean de 5000000 líneas, 50MB de datos.

En el caso de tener salidas de menos de 1KB, como en el caso del módulo de estadísticas, se utilizará la interfaz normal de procfs, la cual se utiliza actualmente en la aplicación Ksensor.

\subsection{Sistema de control de versiones}
Debe decidirse cual es el sistema de control de versiones más adecuado para el proyecto. Esta decisión es muy importante porque hará depender en gran medida las posibilidades de integración con el kernel oficial.

La herramienta electa debe ser eficaz para tamaños de repositorios grandes, proveer flexibilidad en el trabajo, dar opciones de sincronización con otros repositorios. Estas necesidades se especificarán en la sección \reference{scv-criterios}{Criterios de selección}. Es necesario por lo tanto aclarar algunos términos que se van a utilizar en los siguientes puntos con regularidad.

\begin{description}
\item[Sistema de control de versiones] 
Un SCV o VCS por sus siglas en inglés, es una herramienta que facilita a los desarrolladores tener un control de cambios sobre sus proyectos. Se toma un directorio como raíz, y se ordena el proyecto en ella. Cada vez que un desarrollador desea guardar, ejecuta un comando o presiona un botón a través de una interfaz gráfica y se guarda en el repositorio, de tal manera que queda accesible para poder volver a esa versión en cualquier momento.

Este tipo de sistemas posibilitan que en proyectos grandes se pueda hacer un análisis forense de los momentos en los que se han introducido cambios que podían contener algún tipo de regresión o posibiliten marcar algunas versiones como estables para su publicación.

\item[SCV Centralizado o Distribuido]
Hay dos grandes grupos de SCVs, en los que la filosofía de uso y trabajo es muy diferente.

En los centralizados (SCVC), hay un servidor central en el que se hace toda la gestión de versiones. El desarrollador trabaja en su equipo y cuando decide guardar, manda al servidor central la versión, que introduce las versiones de todos los desarrolladores en un único repositorio.

En los distribuidos (SCVD), el servidor es el propio repositorio local, en el que el desarrollador, guarda su trabajo sin necesidad de estar conectado a ningún sitio, estos sistemas están llenos de herramientas para la sincronización de versiones entre diferentes repositorios.

\end{description}

\subsubsection{Estudio de las alternativas}
A continuación se tendrán en consideración los sistemas de control de versiones más relevantes y usados. Se tratará la herramienta que se utiliza actualmente y la que ha sido desarrollada para este tipo de proyectos.

\paragraph{Subversion}
Este sistema de control de versiones es un SVCC que se caracteriza por su simplicidad, linealidad de versiones y gestión de su espacio como un único sistema de ficheros.

Como todo SCVC tiene una versión servidor, que se encarga principalmente de guardar las versiones en una base de datos en la que se pueden configurar permisos de accesos. Soporta varios protocolos de comunicación con sus clientes, como son HTTP, HTTPS, SSH y SVN, su propio protocolo.

Suele tener problemas de configuración de permisos de accesos, ya que todos los guardados, se hacen con el usuario del sistema que se esté utilizando, cambiando muchas veces los permisos, y haciendo que algunos desarrolladores cierren el flujo a otros. También es frecuente encontrar proyectos grandes con errores de integridad de la base de datos que resultan en una imposibilidad de recuperar determinadas versiones.

Algunos otros problemas son la necesidad de atomicidad del repositorio, que implica una indisponibilidad del repositorio durante su uso por otros desarrolladores, o la forma de manejar las colisiones de código, que crean $3+n$ ficheros por colisión $n$.

\paragraph{Git}
Este SCVD se caracteriza por una total adaptación al estilo de trabajo de los grupos de programadores. Como SCVD, tiene características inherentes, como son el hecho de que cada repositorio es independiente, posibilitando al desarrollador guardar su trabajo \textit{offline}. También tiene facilidades para llevar un control de la sincronización con otros repositorios.

Como es distribuido, no hay una versión servidora y una cliente, son todas iguales. La base de datos es local, y está integrada junto al resto de los datos del repositorio. El diseño de Git es relativamente reciente, y se creo de manera que sirviera para el control del desarrollo de kernel, los mismos que desarrollan Linux.

Está diseñado con la integridad como factor principal. Todos las cosas se guardan en una base de datos referenciados por sus hashes, haciendo que cuando se requiere un objeto que ha sido guardado, se computa el hash durante la descompresión, verificando de esa manera que siempre se mantengan los archivos fielmente guardados.

El método de desarrollo para el que está diseñado permite que un desarrollador pueda basar su trabajo, en el trabajo que hay en el repositorio oficial, y tener sus propias ramas de desarrollo con integración continua.

\subsubsection{Criterio de la selección}
\label{scv-criterios}
Para elegir correctamente el SCV que se va a utilizar, se tomarán los siguientes criterios en cuenta.

\begin{description}
\item[{Uso y aprendizaje [10\%]}]
Uno de los principales problemas del desarrollo de un proyecto de kernel es todo el tiempo que se invierte en la familiarización con las herramientas de kernel. Al ser un proyecto tan peculiar, tiene muchas herramientas específicamente creadas para ello.

La inversión de tiempo en la adaptación a un nuevo sistema de control de versiones puede no ser la mejor opción, ya que puede no interesar dependiendo de la longitud del proyecto. En este caso, la inversión en tiempo puede merecer la pena.

\item[{Uso en proyectos similares [20\%]}]
Es importante ver las herramientas que utilizan el resto de proyectos similares, basados en kernel, para su desarrollo. Estos proyectos suelen tener en común la mayor parte de las herramientas utilizadas, al ser un ámbito de desarrollo tan específico.

\item[{Flexibilidad [30\%]}]
Un elemento más importante que el uso y aprendizaje, que se pueden amortizar con el tiempo, es la posibilidad de que la citada herramienta provea de flexibilidad a la hora de trabajar. Uno de los principales hechos en el desarrollo de código, es la posibilidad de hacer las cosas de diferentes maneras, y un sistema que facilite el desarrollo de las nuevas ideas es algo muy positivo para este tipo de proyectos.

Además, el sistema también tiene que facilitar al máximo el desarrollo paralelo, y el concepto de Integración Continua (\textit{CI: Continuous integration}), ya que como el proyecto oficial del kernel de Linux está en continuo desarrollo y se modifican más de 500 líneas de código al día, es importante que el proyecto no quede desactualizado, para evitar tener que hacer otro proyecto que incluya unas modificaciones tan severas en el código.

\item[{Control de cambios [40\%]}]
La característica más importante, y a la que se le ha dado un mayor peso, es a la posibilidad de saber exactamente cuales son los cambios de una versión a otra, quien ha hecho determinados cambios, y sobre todo, la posibilidad de saber quien ha introducido qué cambios y con qué objetivo.

Hay muchas veces en las que los desarrolladores de kernel no documentan los cambios en las líneas de código a través de comentarios, si no que comentan los cambios en los mensajes que se hacen al guardar. El acceso a la información que proporcionan los desarrolladores de esa manera es clave para la actualización del proyecto.

\end{description}

\subsubsection{Selección de la solución}
El sistema de control de versiones que mejor se ajusta a los requerimientos del proyecto es \textit{Git}, tal y como se puede observar en la siguiente tabla.
\begin{center}
\rowcolors{1}{gray}{white}
\begin{tabular}{|c|c|c|c|}
\hline Criterio & Ponderación & Subversion & Git \\ 
\hiderowcolors
\hline Uso y aprendizaje & 10\% & 8/10 & 3/10 \\ 
\hline Uso en proyectos similares & 20\% & 1/20 & 20/20 \\ 
\hline Flexibilidad & 30\% & 10/30 & 30/30 \\ 
\hline Control de cambios & 40\% & 20/40 & 40/40 \\ 
\hline Total & 100\% & 49/100 & 93/100 \\ 
\hline 
\end{tabular}
\end{center}

En este proyecto se ha considerado que aún cuando Subversion es más fácil de utilizar, el hecho de que todos los proyectos centrados alrededor del desarrollo de kernel hayan utilizado Git hace que se pondere en positivo el esfuerzo requerido de aprendizaje.

Además, las facilidades de Git para el control de cambios, permiten ponerse en contacto fácilmente con el desarrollador que ha participado en el código.

\subsection{Método de trabajo y liberación de código}
En esta sección se va a estructurar, ya que es uno de los objetivos del proyecto, la manera en la que se van a guardar las modificaciones de código y la forma en la que se va a organizar el trabajo del proyecto.

La manera de organizar esta sección será diferente a la seguida en otras ocasiones, ya que se organizará como una explicación de los métodos de trabajo, y las formas de ponerlos en práctica.

\subsubsection{Arquitectura del SCVD Git}
Actualmente el repositorio del proyecto se compone por un fichero de parche al kernel, que hay que aplicar y volver a crear cuando se ha seguido el desarrollo, para guardarlo dentro del SCV. Además, en este repositorio se guarda el código del módulo de kernel en el que está contenido todo lo que no es estrictamente necesario de tener en el parche.

Aunque este método de trabajo esté bien, las posibilidades que se abren al utilizar un sistema de control de versiones como Git es que se puede tener un rama de desarrollo dependiente de kernel, y otra paralela en el que se haga todo el desarrollo de una forma independiente, pero con posibilidad de ir integrando el trabajo.

El nuevo sistema, se puede permitir la integración completa en el árbol de código de kernel, siendo de esta manera la más apropiada en caso de que se libere el código.

\subsubsection{Integración del código en el árbol de Linux}
Actualmente la manera de conseguir hacer funcionar la aplicación Ksensor en el árbol de kernel es a través de la aplicación del parche, y posterior compilación del kernel. Una vez parcheado, no hay una manera de no compilar esa parte.

Esta forma de trabajar complica la posibilidad de desarrollar utilidades complementarias pero independientes, pues no se puede discernir entre lo que pertenece al árbol del kernel y lo que no.

Para facilitar el desarrollo, se optará por integrar todo lo posible el trabajo llevado en el grupo de investigación NQAS en el árbol de kernel, para evitar tener que mantener la sincronización entre distintas versiones del código. Por ello, se integrará todo el código en el repositorio.